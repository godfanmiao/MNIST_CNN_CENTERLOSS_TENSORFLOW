{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist_train = pd.read_csv('MNIST_data/train.csv')\n",
    "mnist_test = pd.read_csv('MNIST_data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = mnist_train[['label']][:30000]\n",
    "x_train = mnist_train[['pixel' + str(idx) for idx in range(784)]][:30000]\n",
    "\n",
    "y_dev = mnist_train[['label']][30000:42000]\n",
    "x_dev = mnist_train[['pixel' + str(idx) for idx in range(784)]][30000:42000]\n",
    "\n",
    "x_test = mnist_test[['pixel' + str(idx) for idx in range(784)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      27455\n",
       "253      208\n",
       "254      168\n",
       "255      163\n",
       "252       64\n",
       "128       38\n",
       "29        27\n",
       "191       27\n",
       "64        22\n",
       "63        19\n",
       "13        18\n",
       "251       18\n",
       "3         18\n",
       "241       17\n",
       "246       17\n",
       "7         17\n",
       "5         17\n",
       "21        16\n",
       "154       16\n",
       "92        15\n",
       "226       15\n",
       "217       15\n",
       "141       15\n",
       "2         14\n",
       "6         14\n",
       "76        14\n",
       "152       13\n",
       "218       13\n",
       "22        13\n",
       "139       13\n",
       "       ...  \n",
       "138        4\n",
       "169        3\n",
       "72         3\n",
       "111        3\n",
       "243        3\n",
       "103        3\n",
       "10         3\n",
       "188        3\n",
       "172        3\n",
       "167        3\n",
       "67         3\n",
       "61         3\n",
       "79         3\n",
       "124        3\n",
       "100        3\n",
       "66         3\n",
       "144        3\n",
       "69         3\n",
       "235        3\n",
       "55         2\n",
       "151        2\n",
       "1          2\n",
       "242        2\n",
       "73         2\n",
       "58         2\n",
       "54         1\n",
       "107        1\n",
       "120        1\n",
       "83         1\n",
       "110        1\n",
       "Name: pixel100, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train['pixel100'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train = scaler.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.262867    27455\n",
       " 4.795468      208\n",
       " 4.815461      168\n",
       " 4.835455      163\n",
       " 4.775475       64\n",
       " 2.296291       38\n",
       " 3.555876       27\n",
       " 0.316942       27\n",
       " 1.016712       22\n",
       " 0.996719       19\n",
       " 4.755481       18\n",
       "-0.202887       18\n",
       "-0.002952       18\n",
       "-0.162900       17\n",
       "-0.122913       17\n",
       " 4.655514       17\n",
       " 4.555547       17\n",
       " 0.156995       16\n",
       " 2.816120       16\n",
       " 4.255646       15\n",
       " 4.075705       15\n",
       " 1.576528       15\n",
       " 2.556205       15\n",
       "-0.142906       14\n",
       "-0.222880       14\n",
       " 1.256633       14\n",
       " 0.117008       13\n",
       " 0.756798       13\n",
       " 2.516218       13\n",
       " 2.776133       13\n",
       "             ...  \n",
       " 1.716482        4\n",
       " 1.076692        3\n",
       " 3.495896        3\n",
       " 2.216317        3\n",
       " 1.736475        3\n",
       " 1.796455        3\n",
       " 0.956732        3\n",
       " 2.616185        3\n",
       " 1.956403        3\n",
       "-0.062933        3\n",
       " 4.435586        3\n",
       " 1.316613        3\n",
       " 1.056699        3\n",
       " 3.116021        3\n",
       " 1.116679        3\n",
       " 4.595534        3\n",
       " 3.176001        3\n",
       " 1.176659        3\n",
       " 3.076034        3\n",
       " 4.575540        2\n",
       " 0.836771        2\n",
       " 2.756139        2\n",
       " 1.196653        2\n",
       "-0.242873        2\n",
       " 0.896751        2\n",
       " 2.136343        1\n",
       " 1.396587        1\n",
       " 0.816778        1\n",
       " 1.936409        1\n",
       " 1.876429        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(x_train[:, 100]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_dev = scaler.transform(x_dev)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 274.12, NNZs: 701, Bias: -1331.459863, T: 30000, Avg. loss: 12.473781\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 242.94, NNZs: 701, Bias: -1296.805500, T: 60000, Avg. loss: 7.358001\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 232.15, NNZs: 701, Bias: -1276.785535, T: 90000, Avg. loss: 5.535164\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 221.21, NNZs: 701, Bias: -1263.659855, T: 120000, Avg. loss: 4.598101\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 223.90, NNZs: 701, Bias: -1251.686980, T: 150000, Avg. loss: 4.036676\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 218.16, NNZs: 701, Bias: -1243.320557, T: 180000, Avg. loss: 3.642421\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 219.52, NNZs: 701, Bias: -1235.216011, T: 210000, Avg. loss: 3.361467\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 218.63, NNZs: 701, Bias: -1228.576794, T: 240000, Avg. loss: 3.144381\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 216.73, NNZs: 701, Bias: -1222.949325, T: 270000, Avg. loss: 2.973220\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 215.74, NNZs: 701, Bias: -1217.810000, T: 300000, Avg. loss: 2.835842\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 214.97, NNZs: 701, Bias: -1213.144506, T: 330000, Avg. loss: 2.720995\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 213.31, NNZs: 701, Bias: -1209.076340, T: 360000, Avg. loss: 2.625181\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 213.22, NNZs: 701, Bias: -1205.099495, T: 390000, Avg. loss: 2.544692\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 213.40, NNZs: 701, Bias: -1201.371280, T: 420000, Avg. loss: 2.473490\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 212.33, NNZs: 701, Bias: -1198.126692, T: 450000, Avg. loss: 2.411424\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 211.95, NNZs: 701, Bias: -1194.981850, T: 480000, Avg. loss: 2.356044\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 211.27, NNZs: 701, Bias: -1192.089235, T: 510000, Avg. loss: 2.306655\n",
      "Total training time: 1.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 211.42, NNZs: 701, Bias: -1189.220481, T: 540000, Avg. loss: 2.261999\n",
      "Total training time: 1.07 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 210.74, NNZs: 701, Bias: -1186.662371, T: 570000, Avg. loss: 2.222195\n",
      "Total training time: 1.14 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 209.67, NNZs: 701, Bias: -1184.314265, T: 600000, Avg. loss: 2.186341\n",
      "Total training time: 1.20 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 210.01, NNZs: 701, Bias: -1181.847595, T: 630000, Avg. loss: 2.153694\n",
      "Total training time: 1.26 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 208.48, NNZs: 701, Bias: -1179.823305, T: 660000, Avg. loss: 2.123225\n",
      "Total training time: 1.32 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 208.66, NNZs: 701, Bias: -1177.603375, T: 690000, Avg. loss: 2.095747\n",
      "Total training time: 1.38 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 208.90, NNZs: 701, Bias: -1175.468267, T: 720000, Avg. loss: 2.070156\n",
      "Total training time: 1.43 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 208.02, NNZs: 701, Bias: -1173.616555, T: 750000, Avg. loss: 2.046227\n",
      "Total training time: 1.49 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 207.50, NNZs: 701, Bias: -1171.781590, T: 780000, Avg. loss: 2.024044\n",
      "Total training time: 1.55 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 207.51, NNZs: 701, Bias: -1169.930444, T: 810000, Avg. loss: 2.003499\n",
      "Total training time: 1.61 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 207.16, NNZs: 701, Bias: -1168.212020, T: 840000, Avg. loss: 1.984262\n",
      "Total training time: 1.68 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 206.84, NNZs: 701, Bias: -1166.550682, T: 870000, Avg. loss: 1.966176\n",
      "Total training time: 1.74 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 206.56, NNZs: 701, Bias: -1164.941419, T: 900000, Avg. loss: 1.949141\n",
      "Total training time: 1.81 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 227.88, NNZs: 701, Bias: -1399.545145, T: 30000, Avg. loss: 12.209358\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 202.11, NNZs: 701, Bias: -1375.370092, T: 60000, Avg. loss: 6.872132\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 191.07, NNZs: 701, Bias: -1362.269877, T: 90000, Avg. loss: 5.058341\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 190.77, NNZs: 701, Bias: -1352.226293, T: 120000, Avg. loss: 4.118151\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 189.51, NNZs: 701, Bias: -1344.634346, T: 150000, Avg. loss: 3.543996\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 186.74, NNZs: 701, Bias: -1338.752850, T: 180000, Avg. loss: 3.153822\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 185.91, NNZs: 701, Bias: -1333.575856, T: 210000, Avg. loss: 2.871674\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 184.44, NNZs: 701, Bias: -1329.200019, T: 240000, Avg. loss: 2.658138\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 184.76, NNZs: 701, Bias: -1325.146908, T: 270000, Avg. loss: 2.490972\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 183.77, NNZs: 701, Bias: -1321.701198, T: 300000, Avg. loss: 2.356338\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 184.23, NNZs: 701, Bias: -1318.414203, T: 330000, Avg. loss: 2.246548\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 183.96, NNZs: 701, Bias: -1315.504154, T: 360000, Avg. loss: 2.153772\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 182.79, NNZs: 701, Bias: -1312.958817, T: 390000, Avg. loss: 2.074448\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 182.39, NNZs: 701, Bias: -1310.516960, T: 420000, Avg. loss: 2.006639\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 182.94, NNZs: 701, Bias: -1308.116740, T: 450000, Avg. loss: 1.947611\n",
      "Total training time: 1.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 183.10, NNZs: 701, Bias: -1305.919625, T: 480000, Avg. loss: 1.895309\n",
      "Total training time: 1.07 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 181.68, NNZs: 701, Bias: -1304.077949, T: 510000, Avg. loss: 1.848514\n",
      "Total training time: 1.13 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 182.29, NNZs: 701, Bias: -1302.071744, T: 540000, Avg. loss: 1.807144\n",
      "Total training time: 1.19 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 181.73, NNZs: 701, Bias: -1300.332829, T: 570000, Avg. loss: 1.769713\n",
      "Total training time: 1.26 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 181.67, NNZs: 701, Bias: -1298.619589, T: 600000, Avg. loss: 1.735613\n",
      "Total training time: 1.33 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 182.13, NNZs: 701, Bias: -1296.918432, T: 630000, Avg. loss: 1.704849\n",
      "Total training time: 1.40 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 181.51, NNZs: 701, Bias: -1295.445960, T: 660000, Avg. loss: 1.676570\n",
      "Total training time: 1.47 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 181.73, NNZs: 701, Bias: -1293.925581, T: 690000, Avg. loss: 1.650582\n",
      "Total training time: 1.54 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 180.97, NNZs: 701, Bias: -1292.608436, T: 720000, Avg. loss: 1.626862\n",
      "Total training time: 1.61 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 180.75, NNZs: 701, Bias: -1291.272795, T: 750000, Avg. loss: 1.604851\n",
      "Total training time: 1.68 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 180.38, NNZs: 701, Bias: -1290.013320, T: 780000, Avg. loss: 1.584377\n",
      "Total training time: 1.75 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 180.42, NNZs: 701, Bias: -1288.746359, T: 810000, Avg. loss: 1.565395\n",
      "Total training time: 1.81 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 180.23, NNZs: 701, Bias: -1287.559423, T: 840000, Avg. loss: 1.547692\n",
      "Total training time: 1.87 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 179.88, NNZs: 701, Bias: -1286.435977, T: 870000, Avg. loss: 1.530979\n",
      "Total training time: 1.93 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 180.56, NNZs: 701, Bias: -1285.211623, T: 900000, Avg. loss: 1.515602\n",
      "Total training time: 1.99 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 367.32, NNZs: 701, Bias: -1207.387531, T: 30000, Avg. loss: 25.314103\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 295.92, NNZs: 701, Bias: -1132.613058, T: 60000, Avg. loss: 16.979698\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 271.10, NNZs: 701, Bias: -1088.973615, T: 90000, Avg. loss: 13.707792\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 256.75, NNZs: 701, Bias: -1058.239504, T: 120000, Avg. loss: 11.957964\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 254.49, NNZs: 701, Bias: -1032.867700, T: 150000, Avg. loss: 10.856057\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 248.57, NNZs: 701, Bias: -1013.204288, T: 180000, Avg. loss: 10.067142\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 242.44, NNZs: 701, Bias: -997.030935, T: 210000, Avg. loss: 9.476946\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 242.14, NNZs: 701, Bias: -981.948945, T: 240000, Avg. loss: 9.023389\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 239.12, NNZs: 701, Bias: -969.379410, T: 270000, Avg. loss: 8.651512\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 236.07, NNZs: 701, Bias: -958.337544, T: 300000, Avg. loss: 8.337329\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 233.94, NNZs: 701, Bias: -948.211145, T: 330000, Avg. loss: 8.079790\n",
      "Total training time: 0.88 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 232.31, NNZs: 701, Bias: -938.969915, T: 360000, Avg. loss: 7.852802\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 229.59, NNZs: 701, Bias: -930.754842, T: 390000, Avg. loss: 7.656593\n",
      "Total training time: 1.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 228.75, NNZs: 701, Bias: -922.784193, T: 420000, Avg. loss: 7.483603\n",
      "Total training time: 1.13 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 226.60, NNZs: 701, Bias: -915.717273, T: 450000, Avg. loss: 7.328467\n",
      "Total training time: 1.21 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 224.74, NNZs: 701, Bias: -909.128781, T: 480000, Avg. loss: 7.188126\n",
      "Total training time: 1.29 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 224.78, NNZs: 701, Bias: -902.486115, T: 510000, Avg. loss: 7.063505\n",
      "Total training time: 1.37 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 223.28, NNZs: 701, Bias: -896.617506, T: 540000, Avg. loss: 6.948016\n",
      "Total training time: 1.46 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 221.34, NNZs: 701, Bias: -891.204616, T: 570000, Avg. loss: 6.843411\n",
      "Total training time: 1.54 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 220.97, NNZs: 701, Bias: -885.720586, T: 600000, Avg. loss: 6.747169\n",
      "Total training time: 1.62 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 219.90, NNZs: 701, Bias: -880.705544, T: 630000, Avg. loss: 6.657249\n",
      "Total training time: 1.70 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 219.15, NNZs: 701, Bias: -875.862168, T: 660000, Avg. loss: 6.574326\n",
      "Total training time: 1.78 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 217.75, NNZs: 701, Bias: -871.412705, T: 690000, Avg. loss: 6.496908\n",
      "Total training time: 1.87 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 216.71, NNZs: 701, Bias: -867.086483, T: 720000, Avg. loss: 6.424531\n",
      "Total training time: 1.96 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 216.09, NNZs: 701, Bias: -862.854211, T: 750000, Avg. loss: 6.356601\n",
      "Total training time: 2.03 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 214.83, NNZs: 701, Bias: -858.961291, T: 780000, Avg. loss: 6.292935\n",
      "Total training time: 2.11 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 214.48, NNZs: 701, Bias: -855.006433, T: 810000, Avg. loss: 6.232875\n",
      "Total training time: 2.19 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 214.41, NNZs: 701, Bias: -851.140016, T: 840000, Avg. loss: 6.176134\n",
      "Total training time: 2.27 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 213.55, NNZs: 701, Bias: -847.604601, T: 870000, Avg. loss: 6.122239\n",
      "Total training time: 2.35 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 213.12, NNZs: 701, Bias: -844.098255, T: 900000, Avg. loss: 6.070835\n",
      "Total training time: 2.43 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 322.70, NNZs: 701, Bias: -1235.027038, T: 30000, Avg. loss: 25.299912\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 282.42, NNZs: 701, Bias: -1152.962036, T: 60000, Avg. loss: 17.672628\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    6.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 265.35, NNZs: 701, Bias: -1106.092441, T: 90000, Avg. loss: 14.590194\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 256.20, NNZs: 701, Bias: -1072.415502, T: 120000, Avg. loss: 12.936371\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 249.61, NNZs: 701, Bias: -1046.307884, T: 150000, Avg. loss: 11.860631\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 243.23, NNZs: 701, Bias: -1025.390757, T: 180000, Avg. loss: 11.086513\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 242.08, NNZs: 701, Bias: -1006.809694, T: 210000, Avg. loss: 10.515254\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 239.31, NNZs: 701, Bias: -991.229874, T: 240000, Avg. loss: 10.057220\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 236.76, NNZs: 701, Bias: -977.554405, T: 270000, Avg. loss: 9.688064\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 234.15, NNZs: 701, Bias: -965.502656, T: 300000, Avg. loss: 9.372645\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 230.65, NNZs: 701, Bias: -954.886452, T: 330000, Avg. loss: 9.106359\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 228.93, NNZs: 701, Bias: -944.896211, T: 360000, Avg. loss: 8.873623\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 226.93, NNZs: 701, Bias: -935.843335, T: 390000, Avg. loss: 8.671381\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 224.75, NNZs: 701, Bias: -927.556203, T: 420000, Avg. loss: 8.493283\n",
      "Total training time: 1.04 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 223.84, NNZs: 701, Bias: -919.602325, T: 450000, Avg. loss: 8.334555\n",
      "Total training time: 1.12 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 223.32, NNZs: 701, Bias: -912.119138, T: 480000, Avg. loss: 8.190965\n",
      "Total training time: 1.20 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 221.35, NNZs: 701, Bias: -905.440811, T: 510000, Avg. loss: 8.059659\n",
      "Total training time: 1.28 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 220.43, NNZs: 701, Bias: -898.952225, T: 540000, Avg. loss: 7.940041\n",
      "Total training time: 1.36 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 218.66, NNZs: 701, Bias: -893.046210, T: 570000, Avg. loss: 7.829679\n",
      "Total training time: 1.44 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 218.02, NNZs: 701, Bias: -887.209203, T: 600000, Avg. loss: 7.727985\n",
      "Total training time: 1.52 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 216.68, NNZs: 701, Bias: -881.837522, T: 630000, Avg. loss: 7.633245\n",
      "Total training time: 1.59 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 215.70, NNZs: 701, Bias: -876.659593, T: 660000, Avg. loss: 7.545921\n",
      "Total training time: 1.67 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 214.91, NNZs: 701, Bias: -871.682950, T: 690000, Avg. loss: 7.463716\n",
      "Total training time: 1.75 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 214.48, NNZs: 701, Bias: -866.844828, T: 720000, Avg. loss: 7.387138\n",
      "Total training time: 1.83 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 213.20, NNZs: 701, Bias: -862.425930, T: 750000, Avg. loss: 7.314713\n",
      "Total training time: 1.92 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 212.39, NNZs: 701, Bias: -858.082678, T: 780000, Avg. loss: 7.246772\n",
      "Total training time: 2.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 211.49, NNZs: 701, Bias: -853.949914, T: 810000, Avg. loss: 7.182126\n",
      "Total training time: 2.08 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 211.22, NNZs: 701, Bias: -849.824059, T: 840000, Avg. loss: 7.121121\n",
      "Total training time: 2.16 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 210.59, NNZs: 701, Bias: -845.943106, T: 870000, Avg. loss: 7.063150\n",
      "Total training time: 2.24 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 209.23, NNZs: 701, Bias: -842.378405, T: 900000, Avg. loss: 7.007868\n",
      "Total training time: 2.32 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 347.38, NNZs: 701, Bias: -1409.604399, T: 30000, Avg. loss: 18.514637\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 295.45, NNZs: 701, Bias: -1357.774799, T: 60000, Avg. loss: 11.480546\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 279.45, NNZs: 701, Bias: -1327.912162, T: 90000, Avg. loss: 8.940828\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    8.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 269.13, NNZs: 701, Bias: -1306.847200, T: 120000, Avg. loss: 7.639960\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 266.89, NNZs: 701, Bias: -1289.820338, T: 150000, Avg. loss: 6.837190\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 258.76, NNZs: 701, Bias: -1277.322794, T: 180000, Avg. loss: 6.282598\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 258.97, NNZs: 701, Bias: -1265.439226, T: 210000, Avg. loss: 5.868624\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 257.49, NNZs: 701, Bias: -1255.537005, T: 240000, Avg. loss: 5.553433\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 252.53, NNZs: 701, Bias: -1247.610331, T: 270000, Avg. loss: 5.299764\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 251.49, NNZs: 701, Bias: -1239.870523, T: 300000, Avg. loss: 5.092959\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 250.60, NNZs: 701, Bias: -1232.906927, T: 330000, Avg. loss: 4.922344\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 248.53, NNZs: 701, Bias: -1226.820110, T: 360000, Avg. loss: 4.776285\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 247.67, NNZs: 701, Bias: -1221.035400, T: 390000, Avg. loss: 4.649874\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 246.09, NNZs: 701, Bias: -1215.856559, T: 420000, Avg. loss: 4.541321\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 245.37, NNZs: 701, Bias: -1210.886646, T: 450000, Avg. loss: 4.443897\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 243.99, NNZs: 701, Bias: -1206.401396, T: 480000, Avg. loss: 4.357730\n",
      "Total training time: 1.03 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 243.79, NNZs: 701, Bias: -1201.977709, T: 510000, Avg. loss: 4.281015\n",
      "Total training time: 1.09 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 242.97, NNZs: 701, Bias: -1197.942801, T: 540000, Avg. loss: 4.211697\n",
      "Total training time: 1.16 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 242.78, NNZs: 701, Bias: -1194.013516, T: 570000, Avg. loss: 4.148888\n",
      "Total training time: 1.22 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 241.79, NNZs: 701, Bias: -1190.451594, T: 600000, Avg. loss: 4.091094\n",
      "Total training time: 1.29 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 240.62, NNZs: 701, Bias: -1187.121480, T: 630000, Avg. loss: 4.037906\n",
      "Total training time: 1.35 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 239.72, NNZs: 701, Bias: -1183.908125, T: 660000, Avg. loss: 3.989200\n",
      "Total training time: 1.41 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 239.08, NNZs: 701, Bias: -1180.802046, T: 690000, Avg. loss: 3.944537\n",
      "Total training time: 1.48 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 238.37, NNZs: 701, Bias: -1177.850405, T: 720000, Avg. loss: 3.902973\n",
      "Total training time: 1.54 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 238.45, NNZs: 701, Bias: -1174.870771, T: 750000, Avg. loss: 3.864366\n",
      "Total training time: 1.61 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 238.14, NNZs: 701, Bias: -1172.088953, T: 780000, Avg. loss: 3.828197\n",
      "Total training time: 1.67 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 237.42, NNZs: 701, Bias: -1169.499050, T: 810000, Avg. loss: 3.794386\n",
      "Total training time: 1.74 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 236.73, NNZs: 701, Bias: -1167.008988, T: 840000, Avg. loss: 3.762372\n",
      "Total training time: 1.80 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 236.27, NNZs: 701, Bias: -1164.566372, T: 870000, Avg. loss: 3.732468\n",
      "Total training time: 1.86 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 236.63, NNZs: 701, Bias: -1162.050647, T: 900000, Avg. loss: 3.704352\n",
      "Total training time: 1.93 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 369.52, NNZs: 701, Bias: -1233.632636, T: 30000, Avg. loss: 27.657648\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   10.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 312.48, NNZs: 701, Bias: -1143.122320, T: 60000, Avg. loss: 18.980040\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 287.81, NNZs: 701, Bias: -1090.542982, T: 90000, Avg. loss: 15.639905\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 278.73, NNZs: 701, Bias: -1051.828963, T: 120000, Avg. loss: 13.804671\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 271.71, NNZs: 701, Bias: -1022.257098, T: 150000, Avg. loss: 12.613395\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 264.18, NNZs: 701, Bias: -998.966944, T: 180000, Avg. loss: 11.765963\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 261.40, NNZs: 701, Bias: -978.598227, T: 210000, Avg. loss: 11.133323\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 254.91, NNZs: 701, Bias: -962.058210, T: 240000, Avg. loss: 10.625402\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 253.11, NNZs: 701, Bias: -946.571268, T: 270000, Avg. loss: 10.212783\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 249.45, NNZs: 701, Bias: -933.326379, T: 300000, Avg. loss: 9.869379\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 245.21, NNZs: 701, Bias: -921.674640, T: 330000, Avg. loss: 9.574975\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 244.13, NNZs: 701, Bias: -910.328414, T: 360000, Avg. loss: 9.321621\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 240.73, NNZs: 701, Bias: -900.583082, T: 390000, Avg. loss: 9.100334\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 239.29, NNZs: 701, Bias: -891.146802, T: 420000, Avg. loss: 8.903797\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 237.22, NNZs: 701, Bias: -882.586378, T: 450000, Avg. loss: 8.726341\n",
      "Total training time: 1.10 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 236.05, NNZs: 701, Bias: -874.402772, T: 480000, Avg. loss: 8.567464\n",
      "Total training time: 1.18 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 234.07, NNZs: 701, Bias: -866.991395, T: 510000, Avg. loss: 8.422042\n",
      "Total training time: 1.25 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 232.60, NNZs: 701, Bias: -859.904699, T: 540000, Avg. loss: 8.289555\n",
      "Total training time: 1.33 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 231.35, NNZs: 701, Bias: -853.192748, T: 570000, Avg. loss: 8.167670\n",
      "Total training time: 1.41 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 230.10, NNZs: 701, Bias: -846.864708, T: 600000, Avg. loss: 8.054097\n",
      "Total training time: 1.50 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 228.99, NNZs: 701, Bias: -840.837958, T: 630000, Avg. loss: 7.949578\n",
      "Total training time: 1.58 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 227.41, NNZs: 701, Bias: -835.254208, T: 660000, Avg. loss: 7.852217\n",
      "Total training time: 1.67 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 226.34, NNZs: 701, Bias: -829.806847, T: 690000, Avg. loss: 7.760874\n",
      "Total training time: 1.75 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 224.65, NNZs: 701, Bias: -824.787279, T: 720000, Avg. loss: 7.675027\n",
      "Total training time: 1.83 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 224.24, NNZs: 701, Bias: -819.661001, T: 750000, Avg. loss: 7.594928\n",
      "Total training time: 1.92 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 223.15, NNZs: 701, Bias: -814.928556, T: 780000, Avg. loss: 7.519008\n",
      "Total training time: 1.99 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 221.36, NNZs: 701, Bias: -810.588063, T: 810000, Avg. loss: 7.446997\n",
      "Total training time: 2.07 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 220.55, NNZs: 701, Bias: -806.166249, T: 840000, Avg. loss: 7.378968\n",
      "Total training time: 2.15 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 220.28, NNZs: 701, Bias: -801.773665, T: 870000, Avg. loss: 7.314304\n",
      "Total training time: 2.24 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 219.04, NNZs: 701, Bias: -797.802343, T: 900000, Avg. loss: 7.252804\n",
      "Total training time: 2.32 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 321.29, NNZs: 701, Bias: -1350.859546, T: 30000, Avg. loss: 18.639315\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   12.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 266.31, NNZs: 701, Bias: -1310.817506, T: 60000, Avg. loss: 11.423846\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 251.29, NNZs: 701, Bias: -1286.013733, T: 90000, Avg. loss: 8.694539\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 241.91, NNZs: 701, Bias: -1268.769640, T: 120000, Avg. loss: 7.269192\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 241.09, NNZs: 701, Bias: -1254.350293, T: 150000, Avg. loss: 6.389089\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 237.94, NNZs: 701, Bias: -1243.265473, T: 180000, Avg. loss: 5.777680\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 236.32, NNZs: 701, Bias: -1233.774499, T: 210000, Avg. loss: 5.329790\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 232.39, NNZs: 701, Bias: -1226.035908, T: 240000, Avg. loss: 4.983842\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 230.36, NNZs: 701, Bias: -1219.009657, T: 270000, Avg. loss: 4.711991\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 229.84, NNZs: 701, Bias: -1212.520018, T: 300000, Avg. loss: 4.492082\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 229.96, NNZs: 701, Bias: -1206.563637, T: 330000, Avg. loss: 4.308937\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 228.01, NNZs: 701, Bias: -1201.522652, T: 360000, Avg. loss: 4.154229\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 227.30, NNZs: 701, Bias: -1196.690141, T: 390000, Avg. loss: 4.019671\n",
      "Total training time: 0.88 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 226.30, NNZs: 701, Bias: -1192.277294, T: 420000, Avg. loss: 3.902755\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 225.76, NNZs: 701, Bias: -1188.107862, T: 450000, Avg. loss: 3.800163\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 225.89, NNZs: 701, Bias: -1184.104409, T: 480000, Avg. loss: 3.710797\n",
      "Total training time: 1.08 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 224.86, NNZs: 701, Bias: -1180.567177, T: 510000, Avg. loss: 3.629719\n",
      "Total training time: 1.15 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 223.82, NNZs: 701, Bias: -1177.244329, T: 540000, Avg. loss: 3.557140\n",
      "Total training time: 1.22 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 223.07, NNZs: 701, Bias: -1174.072965, T: 570000, Avg. loss: 3.490818\n",
      "Total training time: 1.29 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 222.94, NNZs: 701, Bias: -1170.958218, T: 600000, Avg. loss: 3.431674\n",
      "Total training time: 1.36 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 223.54, NNZs: 701, Bias: -1167.861088, T: 630000, Avg. loss: 3.377277\n",
      "Total training time: 1.43 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 222.84, NNZs: 701, Bias: -1165.150073, T: 660000, Avg. loss: 3.326904\n",
      "Total training time: 1.50 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 222.18, NNZs: 701, Bias: -1162.563066, T: 690000, Avg. loss: 3.280414\n",
      "Total training time: 1.57 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 221.52, NNZs: 701, Bias: -1160.093473, T: 720000, Avg. loss: 3.237285\n",
      "Total training time: 1.64 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 221.30, NNZs: 701, Bias: -1157.651718, T: 750000, Avg. loss: 3.197352\n",
      "Total training time: 1.70 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 220.53, NNZs: 701, Bias: -1155.415581, T: 780000, Avg. loss: 3.160273\n",
      "Total training time: 1.77 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 219.84, NNZs: 701, Bias: -1153.254212, T: 810000, Avg. loss: 3.125153\n",
      "Total training time: 1.84 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 220.04, NNZs: 701, Bias: -1151.007882, T: 840000, Avg. loss: 3.092936\n",
      "Total training time: 1.91 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 219.67, NNZs: 701, Bias: -1148.950686, T: 870000, Avg. loss: 3.062171\n",
      "Total training time: 1.98 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 219.41, NNZs: 701, Bias: -1146.949003, T: 900000, Avg. loss: 3.033643\n",
      "Total training time: 2.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 313.44, NNZs: 701, Bias: -1420.493912, T: 30000, Avg. loss: 18.071551\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 275.92, NNZs: 701, Bias: -1373.669971, T: 60000, Avg. loss: 11.421117\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 262.23, NNZs: 701, Bias: -1347.093850, T: 90000, Avg. loss: 8.971214\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   14.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 256.88, NNZs: 701, Bias: -1327.473725, T: 120000, Avg. loss: 7.637317\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 252.75, NNZs: 701, Bias: -1312.447683, T: 150000, Avg. loss: 6.791760\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 252.87, NNZs: 701, Bias: -1299.631573, T: 180000, Avg. loss: 6.204182\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 249.12, NNZs: 701, Bias: -1289.620346, T: 210000, Avg. loss: 5.774155\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 247.52, NNZs: 701, Bias: -1280.654342, T: 240000, Avg. loss: 5.440679\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 247.67, NNZs: 701, Bias: -1272.461786, T: 270000, Avg. loss: 5.173601\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 246.63, NNZs: 701, Bias: -1265.362525, T: 300000, Avg. loss: 4.954563\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 245.01, NNZs: 701, Bias: -1259.106427, T: 330000, Avg. loss: 4.772418\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 242.79, NNZs: 701, Bias: -1253.537365, T: 360000, Avg. loss: 4.616152\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 241.36, NNZs: 701, Bias: -1248.316968, T: 390000, Avg. loss: 4.483511\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 241.92, NNZs: 701, Bias: -1243.134830, T: 420000, Avg. loss: 4.366587\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 241.19, NNZs: 701, Bias: -1238.559345, T: 450000, Avg. loss: 4.263919\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 240.35, NNZs: 701, Bias: -1234.317206, T: 480000, Avg. loss: 4.172504\n",
      "Total training time: 1.05 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 238.78, NNZs: 701, Bias: -1230.492473, T: 510000, Avg. loss: 4.090742\n",
      "Total training time: 1.12 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 238.55, NNZs: 701, Bias: -1226.650348, T: 540000, Avg. loss: 4.016787\n",
      "Total training time: 1.18 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 238.46, NNZs: 701, Bias: -1222.992092, T: 570000, Avg. loss: 3.949439\n",
      "Total training time: 1.25 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 237.16, NNZs: 701, Bias: -1219.768676, T: 600000, Avg. loss: 3.888091\n",
      "Total training time: 1.31 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 237.39, NNZs: 701, Bias: -1216.421669, T: 630000, Avg. loss: 3.832487\n",
      "Total training time: 1.38 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 236.65, NNZs: 701, Bias: -1213.417744, T: 660000, Avg. loss: 3.780900\n",
      "Total training time: 1.44 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 237.12, NNZs: 701, Bias: -1210.324912, T: 690000, Avg. loss: 3.733590\n",
      "Total training time: 1.51 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 235.96, NNZs: 701, Bias: -1207.677142, T: 720000, Avg. loss: 3.689396\n",
      "Total training time: 1.57 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 235.36, NNZs: 701, Bias: -1205.039899, T: 750000, Avg. loss: 3.648123\n",
      "Total training time: 1.64 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 234.81, NNZs: 701, Bias: -1202.507440, T: 780000, Avg. loss: 3.609574\n",
      "Total training time: 1.70 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 234.87, NNZs: 701, Bias: -1199.962125, T: 810000, Avg. loss: 3.573732\n",
      "Total training time: 1.77 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 233.77, NNZs: 701, Bias: -1197.734116, T: 840000, Avg. loss: 3.539913\n",
      "Total training time: 1.83 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 233.95, NNZs: 701, Bias: -1195.345859, T: 870000, Avg. loss: 3.508429\n",
      "Total training time: 1.90 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 233.76, NNZs: 701, Bias: -1193.111778, T: 900000, Avg. loss: 3.478576\n",
      "Total training time: 1.96 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 368.70, NNZs: 701, Bias: -1301.641038, T: 30000, Avg. loss: 34.345254\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   16.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 326.93, NNZs: 701, Bias: -1184.578291, T: 60000, Avg. loss: 24.364848\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 307.62, NNZs: 701, Bias: -1118.842022, T: 90000, Avg. loss: 20.309300\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 295.12, NNZs: 701, Bias: -1072.179637, T: 120000, Avg. loss: 18.063541\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 283.69, NNZs: 701, Bias: -1036.820465, T: 150000, Avg. loss: 16.597222\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 275.85, NNZs: 701, Bias: -1008.005599, T: 180000, Avg. loss: 15.539644\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 274.79, NNZs: 701, Bias: -982.279725, T: 210000, Avg. loss: 14.716336\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 269.14, NNZs: 701, Bias: -961.467510, T: 240000, Avg. loss: 14.056934\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 267.02, NNZs: 701, Bias: -942.346023, T: 270000, Avg. loss: 13.519322\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 262.05, NNZs: 701, Bias: -926.240218, T: 300000, Avg. loss: 13.062693\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 259.99, NNZs: 701, Bias: -911.001659, T: 330000, Avg. loss: 12.670668\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 256.89, NNZs: 701, Bias: -897.543544, T: 360000, Avg. loss: 12.329248\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 254.49, NNZs: 701, Bias: -885.097256, T: 390000, Avg. loss: 12.025991\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 251.86, NNZs: 701, Bias: -873.735758, T: 420000, Avg. loss: 11.755153\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 250.60, NNZs: 701, Bias: -862.865839, T: 450000, Avg. loss: 11.512521\n",
      "Total training time: 1.10 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 247.13, NNZs: 701, Bias: -853.391057, T: 480000, Avg. loss: 11.291778\n",
      "Total training time: 1.18 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 245.83, NNZs: 701, Bias: -843.956649, T: 510000, Avg. loss: 11.090196\n",
      "Total training time: 1.25 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 244.18, NNZs: 701, Bias: -835.214909, T: 540000, Avg. loss: 10.904008\n",
      "Total training time: 1.33 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 242.94, NNZs: 701, Bias: -826.877588, T: 570000, Avg. loss: 10.732032\n",
      "Total training time: 1.40 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 240.53, NNZs: 701, Bias: -819.353878, T: 600000, Avg. loss: 10.572036\n",
      "Total training time: 1.48 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 239.46, NNZs: 701, Bias: -811.859312, T: 630000, Avg. loss: 10.423369\n",
      "Total training time: 1.56 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 237.79, NNZs: 701, Bias: -804.921490, T: 660000, Avg. loss: 10.284332\n",
      "Total training time: 1.63 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 236.59, NNZs: 701, Bias: -798.207709, T: 690000, Avg. loss: 10.153802\n",
      "Total training time: 1.71 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 236.23, NNZs: 701, Bias: -791.559079, T: 720000, Avg. loss: 10.030583\n",
      "Total training time: 1.79 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 234.57, NNZs: 701, Bias: -785.584388, T: 750000, Avg. loss: 9.914682\n",
      "Total training time: 1.87 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 232.88, NNZs: 701, Bias: -779.882757, T: 780000, Avg. loss: 9.804700\n",
      "Total training time: 1.95 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 232.02, NNZs: 701, Bias: -774.185252, T: 810000, Avg. loss: 9.700675\n",
      "Total training time: 2.03 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 230.73, NNZs: 701, Bias: -768.841846, T: 840000, Avg. loss: 9.601342\n",
      "Total training time: 2.10 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 229.79, NNZs: 701, Bias: -763.611861, T: 870000, Avg. loss: 9.506933\n",
      "Total training time: 2.18 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 229.18, NNZs: 701, Bias: -758.478394, T: 900000, Avg. loss: 9.416928\n",
      "Total training time: 2.26 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 354.93, NNZs: 701, Bias: -1357.590213, T: 30000, Avg. loss: 26.144872\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   19.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 303.11, NNZs: 701, Bias: -1290.912874, T: 60000, Avg. loss: 17.066220\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 288.06, NNZs: 701, Bias: -1252.348347, T: 90000, Avg. loss: 13.577191\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 278.75, NNZs: 701, Bias: -1224.891955, T: 120000, Avg. loss: 11.664519\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 276.55, NNZs: 701, Bias: -1202.780930, T: 150000, Avg. loss: 10.447118\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 271.20, NNZs: 701, Bias: -1185.581580, T: 180000, Avg. loss: 9.585233\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 268.54, NNZs: 701, Bias: -1170.677385, T: 210000, Avg. loss: 8.948037\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 266.81, NNZs: 701, Bias: -1157.721442, T: 240000, Avg. loss: 8.454940\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 264.20, NNZs: 701, Bias: -1146.608072, T: 270000, Avg. loss: 8.052843\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 263.63, NNZs: 701, Bias: -1136.326131, T: 300000, Avg. loss: 7.722582\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 262.19, NNZs: 701, Bias: -1127.255327, T: 330000, Avg. loss: 7.444220\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 260.47, NNZs: 701, Bias: -1119.095690, T: 360000, Avg. loss: 7.207285\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 258.98, NNZs: 701, Bias: -1111.562171, T: 390000, Avg. loss: 7.001915\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 257.88, NNZs: 701, Bias: -1104.555249, T: 420000, Avg. loss: 6.821190\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 256.05, NNZs: 701, Bias: -1098.225134, T: 450000, Avg. loss: 6.661520\n",
      "Total training time: 1.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 255.27, NNZs: 701, Bias: -1092.116680, T: 480000, Avg. loss: 6.517979\n",
      "Total training time: 1.06 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 254.90, NNZs: 701, Bias: -1086.318131, T: 510000, Avg. loss: 6.389107\n",
      "Total training time: 1.13 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 253.68, NNZs: 701, Bias: -1081.039336, T: 540000, Avg. loss: 6.273671\n",
      "Total training time: 1.20 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 252.63, NNZs: 701, Bias: -1076.038833, T: 570000, Avg. loss: 6.167320\n",
      "Total training time: 1.26 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 252.47, NNZs: 701, Bias: -1071.112701, T: 600000, Avg. loss: 6.069918\n",
      "Total training time: 1.33 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 250.77, NNZs: 701, Bias: -1066.795949, T: 630000, Avg. loss: 5.980490\n",
      "Total training time: 1.40 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 249.72, NNZs: 701, Bias: -1062.555307, T: 660000, Avg. loss: 5.897344\n",
      "Total training time: 1.47 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 249.86, NNZs: 701, Bias: -1058.240176, T: 690000, Avg. loss: 5.820552\n",
      "Total training time: 1.54 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 248.16, NNZs: 701, Bias: -1054.543740, T: 720000, Avg. loss: 5.748820\n",
      "Total training time: 1.61 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 248.61, NNZs: 701, Bias: -1050.515226, T: 750000, Avg. loss: 5.682328\n",
      "Total training time: 1.67 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 247.73, NNZs: 701, Bias: -1046.959826, T: 780000, Avg. loss: 5.619579\n",
      "Total training time: 1.74 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 246.85, NNZs: 701, Bias: -1043.550314, T: 810000, Avg. loss: 5.560244\n",
      "Total training time: 1.81 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 246.49, NNZs: 701, Bias: -1040.156203, T: 840000, Avg. loss: 5.504746\n",
      "Total training time: 1.88 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 245.63, NNZs: 701, Bias: -1037.010158, T: 870000, Avg. loss: 5.452241\n",
      "Total training time: 1.94 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 245.59, NNZs: 701, Bias: -1033.783636, T: 900000, Avg. loss: 5.403072\n",
      "Total training time: 2.01 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   21.1s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "lr = SGDClassifier(loss = 'log', n_iter=30, verbose=10)\n",
    "lr.fit(x_train, y_train)\n",
    "y_dev_predict = lr.predict(x_dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91316666666666668"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_dev, y_dev_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_predict = lr.predict(x_test)\n",
    "pd.DataFrame({\"ImageId\": range(1, len(x_test) + 1), \"Label\": y_test_predict}).to_csv('MNIST_data/sgdc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
